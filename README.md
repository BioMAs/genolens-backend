# Genolens Backend

Backend API for the Genolens bioinformatics platform, built with FastAPI, SQLAlchemy, and Celery.

## ðŸš€ Features

- **High Performance API**: Built with FastAPI and async Python.
- **Data Processing**: Specialized parsing for bio-data (CSV/TSV/Parquet) for DEG, Enrichment, and Counts.
- **Asynchronous Tasks**: Celery workers backed by Redis for heavy data ingestion and processing.
- **AI Integration**: Integration with Ollama for localized LLM biological interpretation.
- **Security**: Supabase Auth integration.
- **Storage**: Hybrid storage approach using PostgreSQL for metadata/relational data and Parquet files for large biological datasets.

## ðŸ›  Prerequisites

- **Docker** and **Docker Compose**
- **Python 3.10+** (if running locally without Docker)
- **Supabase** account (or local instance) for Auth and Storage buckets.

## ðŸ“¦ Installation & Setup

### 1. Environment Variables

Copy the example environment file and configure it:

```bash
cp .env.example .env
```

You need to fill in at least:
- `DATABASE_URL` (PostgreSQL connection string)
- `SUPABASE_URL` and keys
- `REDIS_URL`

### 2. Running with Docker (Recommended)

To start the API, Worker, Database, Redis, and Ollama:

```bash
docker-compose up --build
```

The API will be available at `http://localhost:8000`.
API Documentation (Swagger UI): `http://localhost:8000/docs`.

### 3. Running Locally (Development)

Ensure you have a PostgreSQL database and Redis running locally (or via docker-compose).

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Run migrations
alembic upgrade head

# Start API
uvicorn app.main:app --reload
```

To run the worker locally:
```bash
celery -A app.worker.celery_app worker --loglevel=info -Q celery,default,data_processing
```

## ðŸ“‚ Project Structure

```
backend/
â”œâ”€â”€ alembic/              # Database migrations
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/              # API endpoints (Routes)
â”‚   â”œâ”€â”€ core/             # Config, Security, Auth
â”‚   â”œâ”€â”€ db/               # Database session and base models
â”‚   â”œâ”€â”€ models/           # SQLAlchemy models
â”‚   â”œâ”€â”€ schemas/          # Pydantic schemas (Request/Response)
â”‚   â”œâ”€â”€ services/         # Business logic (Data processing, AI, stats)
â”‚   â””â”€â”€ worker/           # Celery task definitions
â”œâ”€â”€ sql/                  # Raw SQL schemas (reference)
â”œâ”€â”€ scripts/              # Helper scripts (setup, ingestion, testing)
â””â”€â”€ tests/                # Pytest tests
```

## ðŸ§ª Testing

```bash
pytest
```

## ðŸš¢ Production

Use the provided `docker-compose.prod.yml` for production deployments. It includes Traefik labels for reverse proxy configuration.

```bash
docker-compose -f docker-compose.prod.yml up -d
```
